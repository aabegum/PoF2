"""
DATA LEAKAGE REMOVAL
Turkish EDAÅ PoF Prediction Project

Purpose:
- Identify and remove features that would cause data leakage
- Data leakage = features that contain information about the target period
- Ensures model only uses information available at prediction time

Data Leakage Rules:
1. LEAKY: Features that include target period data (e.g., ArÄ±za_SayÄ±sÄ±_12ay for 12M prediction)
2. LEAKY: Aggregations calculated on target period data
3. LEAKY: Features derived from future knowledge
4. SAFE: Historical data from BEFORE prediction time
5. SAFE: Static attributes (age, equipment class, location, capacity)

Input:  data/features_selected.csv (~25-35 features)
Output: data/features_selected_clean.csv (~15-25 features)

Author: Data Analytics Team
Date: 2025
Version: 2.0
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Display settings
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)

print("="*100)
print(" "*30 + "DATA LEAKAGE REMOVAL")
print(" "*35 + "PoF Prediction")
print("="*100)

# ============================================================================
# STEP 1: LOAD SELECTED FEATURES
# ============================================================================
print("\n" + "="*100)
print("STEP 1: LOADING SELECTED FEATURES")
print("="*100)

data_path = Path('data/features_selected.csv')

if not data_path.exists():
    print(f"\nâŒ ERROR: File not found at {data_path}")
    print("Please run 05_feature_selection.py first!")
    exit(1)

print(f"\nâœ“ Loading from: {data_path}")
df = pd.read_csv(data_path)
print(f"âœ“ Loaded: {df.shape[0]:,} equipment Ã— {df.shape[1]} features")

original_features = df.columns.tolist()

# ============================================================================
# STEP 2: DEFINE LEAKAGE RULES
# ============================================================================
print("\n" + "="*100)
print("STEP 2: DEFINING DATA LEAKAGE RULES")
print("="*100)

print("\nğŸ“‹ Data Leakage Categories:")
print("\n1. LEAKY - Recent Failure Counts (include target period):")
print("   â€¢ ArÄ±za_SayÄ±sÄ±_3ay, _6ay, _12ay (recent failure counts)")
print("   â€¢ Any aggregations based on these (Class_Avg, Cluster_Avg)")
print("   â€¢ Recent_Failure_Intensity (3M/12M ratio)")

print("\n2. LEAKY - Future-Looking Features:")
print("   â€¢ Risk scores calculated FROM target period failures")
print("   â€¢ Any feature derived from 'looking ahead' at failures")

print("\n3. SAFE - Historical Patterns:")
print("   â€¢ Toplam_ArÄ±za_Sayisi_Lifetime (entire history)")
print("   â€¢ MTBF_GÃ¼n (mean time between failures)")
print("   â€¢ Failure_Rate_Per_Year (lifetime average)")
print("   â€¢ Son_ArÄ±za_Gun_Sayisi (days since last failure)")

print("\n4. SAFE - Static Attributes:")
print("   â€¢ Ekipman_YaÅŸÄ±_YÄ±l (equipment age)")
print("   â€¢ Yas_Beklenen_Omur_Orani (age ratio)")
print("   â€¢ Equipment_Class_Primary (equipment type)")
print("   â€¢ Geographic location and cluster")
print("   â€¢ Customer impact (infrastructure-based)")

# ============================================================================
# STEP 3: IDENTIFY LEAKY FEATURES
# ============================================================================
print("\n" + "="*100)
print("STEP 3: IDENTIFYING LEAKY FEATURES")
print("="*100)

print("\n--- Scanning for Leaky Feature Patterns ---")

leaky_features = []
leaky_reasons = {}

for col in original_features:
    reason = None

    # Rule 1: Recent failure counts (3/6/12 months)
    if 'ArÄ±za_SayÄ±sÄ±_3ay' in col or 'ArÄ±za_SayÄ±sÄ±_6ay' in col or 'ArÄ±za_SayÄ±sÄ±_12ay' in col:
        if col != 'Toplam_ArÄ±za_Sayisi_Lifetime':  # Lifetime is OK
            reason = "Recent failure count (includes target period)"

    # Rule 2: Aggregations based on recent failures
    elif any(x in col for x in ['_12ay_Class_Avg', '_12ay_Cluster_Avg', '_6ay_Class_Avg', '_3ay_Class_Avg']):
        reason = "Aggregation based on recent failures (target period)"

    # Rule 3: Recent failure intensity/acceleration
    elif 'Recent_Failure_Intensity' in col or 'Failure_Acceleration' in col:
        reason = "Recent failure intensity (uses target period)"

    # Rule 4: Risk scores if based on recent failures
    elif 'Recent_Failure_Risk_Score' in col:
        reason = "Risk score based on recent failures"

    # Rule 5: Age-Failure interaction (if using recent failures)
    elif 'Age_Failure_Interaction' in col:
        reason = "Interaction with recent failure counts"

    # Rule 6: Failure-free flags for recent periods
    elif 'Failure_Free_3M' in col:
        reason = "Recent failure-free flag"

    # Rule 7: Time since last normalized (if recent)
    elif 'Time_Since_Last_Normalized' in col:
        reason = "Normalized time since last failure (recent)"

    if reason:
        leaky_features.append(col)
        leaky_reasons[col] = reason

print(f"\nâš ï¸  Identified {len(leaky_features)} leaky features:")
for feat in leaky_features:
    print(f"   âŒ {feat:<50} â†’ {leaky_reasons[feat]}")

# ============================================================================
# STEP 4: DEFINE SAFE FEATURES
# ============================================================================
print("\n" + "="*100)
print("STEP 4: DEFINING SAFE FEATURE SET")
print("="*100)

# Remove leaky features
safe_features = [col for col in original_features if col not in leaky_features]

print(f"\nâœ“ {len(safe_features)} safe features identified")

# Categorize safe features
id_features = [col for col in safe_features if 'ID' in col or col == 'Ekipman_ID']
age_features = [col for col in safe_features if 'YaÅŸ' in col or 'Age' in col or 'Ã–mÃ¼r' in col or 'Life' in col]
historical_features = [col for col in safe_features if 'Lifetime' in col or 'MTBF' in col or 'Reliability' in col or 'Failure_Rate_Per_Year' in col]
location_features = [col for col in safe_features if 'Geographic' in col or 'Cluster' in col or 'KOORDINAT' in col or 'Ä°l' in col or 'Ä°lÃ§e' in col]
equipment_features = [col for col in safe_features if 'Equipment' in col or 'Ekipman' in col or 'Class' in col]
customer_features = [col for col in safe_features if 'Customer' in col or 'MÃ¼ÅŸteri' in col]
composite_features = [col for col in safe_features if 'Risk' in col or 'Score' in col or 'Interaction' in col]

# Note: Some composite features might be in multiple categories
# Filter out composites that are already categorized
other_features = [col for col in safe_features if col not in
                 id_features + age_features + historical_features +
                 location_features + equipment_features + customer_features + composite_features]

print("\n--- Safe Features by Category ---")
print(f"\n1. ID Features ({len(id_features)}):")
for feat in id_features:
    print(f"   âœ“ {feat}")

print(f"\n2. Age/Life Features ({len(age_features)}):")
for feat in age_features:
    print(f"   âœ“ {feat}")

print(f"\n3. Historical Failure Features ({len(historical_features)}):")
for feat in historical_features:
    print(f"   âœ“ {feat}")

print(f"\n4. Location/Geographic Features ({len(location_features)}):")
for feat in location_features:
    print(f"   âœ“ {feat}")

print(f"\n5. Equipment Type Features ({len(equipment_features)}):")
for feat in equipment_features:
    print(f"   âœ“ {feat}")

print(f"\n6. Customer Impact Features ({len(customer_features)}):")
for feat in customer_features:
    print(f"   âœ“ {feat}")

print(f"\n7. Composite/Risk Features ({len(composite_features)}):")
for feat in composite_features:
    # Check if composite feature uses safe components
    if any(x in feat for x in ['12ay', '6ay', '3ay', 'Recent']):
        print(f"   âš ï¸  {feat} (may contain recent data - verify manually)")
    else:
        print(f"   âœ“ {feat}")

if len(other_features) > 0:
    print(f"\n8. Other Features ({len(other_features)}):")
    for feat in other_features:
        print(f"   âœ“ {feat}")

# ============================================================================
# STEP 5: MANUAL REVIEW WARNINGS
# ============================================================================
print("\n" + "="*100)
print("STEP 5: MANUAL REVIEW WARNINGS")
print("="*100)

print("\nâš ï¸  Features requiring manual review:")

# Check for potentially problematic features
review_needed = []

for feat in safe_features:
    if 'Risk_Category' in feat:
        review_needed.append((feat, "Verify Risk_Category is not based on target period"))
    elif 'Composite_PoF_Risk_Score' in feat:
        review_needed.append((feat, "Verify composite score doesn't use recent failures"))
    elif 'Class_Avg' in feat or 'Cluster_Avg' in feat:
        if not any(x in feat for x in ['12ay', '6ay', '3ay']):  # Already filtered
            review_needed.append((feat, "Verify aggregation period doesn't overlap with target"))

if len(review_needed) > 0:
    for feat, warning in review_needed:
        print(f"   âš ï¸  {feat}")
        print(f"       â†’ {warning}")
else:
    print("   âœ“ No features requiring manual review")

# ============================================================================
# STEP 6: SAVE CLEAN FEATURES
# ============================================================================
print("\n" + "="*100)
print("STEP 6: SAVING CLEAN FEATURE SET")
print("="*100)

# Create clean dataframe
df_clean = df[safe_features].copy()

output_path = Path('data/features_selected_clean.csv')
print(f"\nğŸ’¾ Saving to: {output_path}")
df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')

print(f"âœ… Successfully saved!")
print(f"   Records: {len(df_clean):,}")
print(f"   Features: {len(df_clean.columns)}")
print(f"   File size: {output_path.stat().st_size / 1024**2:.2f} MB")

# Save leakage report
print("\nğŸ“‹ Creating leakage analysis report...")

report_data = []
for feat in original_features:
    is_leaky = feat in leaky_features
    report_data.append({
        'Feature': feat,
        'Status': 'LEAKY' if is_leaky else 'SAFE',
        'Reason': leaky_reasons.get(feat, 'No leakage detected'),
        'Included_In_Clean_Set': not is_leaky
    })

report_df = pd.DataFrame(report_data)
report_path = Path('outputs/feature_selection/leakage_analysis.csv')
report_path.parent.mkdir(parents=True, exist_ok=True)
report_df.to_csv(report_path, index=False)
print(f"âœ“ Leakage analysis saved to: {report_path}")

# ============================================================================
# STEP 7: SUMMARY
# ============================================================================
print("\n" + "="*100)
print("DATA LEAKAGE REMOVAL COMPLETE")
print("="*100)

print(f"\nğŸ“Š LEAKAGE REMOVAL SUMMARY:")
print(f"   Original features: {len(original_features)}")
print(f"   Leaky features removed: {len(leaky_features)}")
print(f"   Safe features retained: {len(safe_features)}")
print(f"   Retention rate: {len(safe_features)/len(original_features)*100:.1f}%")

print(f"\nğŸ“‚ OUTPUT FILES:")
print(f"   â€¢ {output_path} ({len(safe_features)} features)")
print(f"   â€¢ {report_path} (detailed analysis)")

print(f"\nğŸš€ READY FOR MODEL TRAINING:")
print(f"   âœ“ No data leakage from target period")
print(f"   âœ“ Only historical and static features included")
print(f"   âœ“ Clean dataset for unbiased model training")

print("\nğŸ’¡ IMPORTANT NOTES:")
print("   â€¢ This script removes OBVIOUS leakage patterns")
print("   â€¢ Manual review recommended for composite features")
print("   â€¢ Verify aggregations don't overlap with prediction window")
print("   â€¢ For multi-horizon predictions (3M/6M/12M), ensure features are calculated")
print("     from data BEFORE each prediction window")

print("\n" + "="*100)
print(f"{'LEAKAGE REMOVAL PIPELINE COMPLETE':^100}")
print("="*100)
